{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/adipilat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate\n",
    "from keras import optimizers\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# reserve only the 30% of the GPU memory\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "width = 50\n",
    "height = 10\n",
    "channels = 4 #3\n",
    "classes = 4\n",
    "epochs = 100\n",
    "dataset_dir = '/data/user/adipilat/ParticleID/genEvts/new_datasets/padded/'\n",
    "save_dir = '/data/user/adipilat/ParticleID/models/'\n",
    "padding = 'padding' + str(height)\n",
    "model_name= padding +'_PCAModel'\n",
    "history_name = model_name + '_history'\n",
    "\n",
    "# This dictionary should be extended to new classes and antiparticles\n",
    "class_labels = {22:0, 11:1, 13:2, 211:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file pion_c_newPadded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:51<02:33, 51.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file gamma_newPadded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [01:41<01:42, 51.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file electron_newPadded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [02:32<00:50, 50.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file muon_newPadded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:23<00:00, 50.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# arrays of data needed for training\n",
    "\n",
    "data_array = []\n",
    "pid_array = []\n",
    "en_array = []\n",
    "\n",
    "# read dataset\n",
    "files = [f for f in os.listdir(dataset_dir) if f.endswith(\"h5\")]\n",
    "\n",
    "for name in tqdm(files):\n",
    "    print(\"Reading file\", name)\n",
    "    data = pd.read_hdf(dataset_dir + name)\n",
    "    num_tracks = int(0.9 * data.trackster.max()) #with the new dataset, we'll split into training and test\n",
    "    for i in range(1, num_tracks+1):\n",
    "        track = data[data['trackster'] == i]\n",
    "#         img = np.array([track.E.values, track.eta.values, track.phi.values]).T.reshape(width, height, channels)\n",
    "#         img = np.array([track.E.values, np.abs(track.eta.values-track.eta_mean.values), np.abs(track.phi.values-track.phi_mean.values)]).T.reshape(width, height, channels)\n",
    "        img = np.array([track.E.values, track.x_pca.values, track.y_pca.values, track.z_pca.values]).T.reshape(width, height, channels)\n",
    "        pid_vals, pid_counts = np.unique(track[track['cpID'] != 0].cpID, return_counts=True)\n",
    "        pid_index = np.argmax(pid_counts)\n",
    "        pid = int(pid_vals[pid_index])\n",
    "        pid = class_labels[pid]\n",
    "        en_value = track[track['genE'] != 0].genE.max()\n",
    "        data_array.append(img)\n",
    "        pid_array.append(pid)\n",
    "        en_array.append(en_value)\n",
    "\n",
    "data_array = np.array(data_array)\n",
    "pid_array = np.array(pid_array)\n",
    "pid_array = keras.utils.to_categorical(pid_array, num_classes=classes, dtype='float32')\n",
    "en_array = np.array(en_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 50, 10, 4)\n",
      "(36000, 4)\n",
      "(36000,)\n"
     ]
    }
   ],
   "source": [
    "print(data_array.shape)\n",
    "print(pid_array.shape)\n",
    "print(en_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Energy Value: 213.90352475881576\n",
      "Std Energy Value: 108.05413626100672\n"
     ]
    }
   ],
   "source": [
    "mean_en = np.mean(en_array)\n",
    "std_en = np.std(en_array)\n",
    "print('Mean Energy Value: {}'.format(mean_en))\n",
    "print('Std Energy Value: {}'.format(std_en))\n",
    "\n",
    "en_array_norm = (en_array - mean_en)/std_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 50, 10, 4)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 50, 10, 3)    63          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 50, 10, 3)    84          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 50, 10, 3)    84          conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1500)         0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 512)          768512      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128)          65664       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_id1 (Dense)               (None, 64)           8256        dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_er1 (Dense)               (None, 64)           8256        dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_id2 (Dense)               (None, 16)           1040        dense_id1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_er2 (Dense)               (None, 16)           1040        dense_er1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pid_output (Dense)              (None, 4)            68          dense_id2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "enreg_output (Dense)            (None, 1)            17          dense_er2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 853,084\n",
      "Trainable params: 853,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model created!\n"
     ]
    }
   ],
   "source": [
    "print('Creating model...')\n",
    "\n",
    "def full_model():\n",
    "\n",
    "    input_img = Input(shape=(width, height, channels), name='input')\n",
    "    \n",
    "    conv = Conv2D(3, (5,1), activation='relu', padding='same', kernel_initializer='random_uniform', data_format='channels_last', name='conv1')(input_img)\n",
    "    conv = Conv2D(3, (3,3), activation='relu', padding='same', kernel_initializer='random_uniform', data_format='channels_last', name='conv2')(conv)\n",
    "    conv = Conv2D(3, (3,3), activation='relu', padding='same', kernel_initializer='random_uniform', data_format='channels_last', name='conv3')(conv)\n",
    "\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    dense = Dense(512, activation='relu', kernel_initializer='random_uniform', name='dense1')(flat)\n",
    "#     drop = Dropout(0.4)(dense)\n",
    "    dense = Dense(128, activation='relu', kernel_initializer='random_uniform', name='dense2')(dense)\n",
    "#     drop = Dropout(0.5)(dense)\n",
    "\n",
    "    dense_id = Dense(64, activation='relu', kernel_initializer='random_uniform', name='dense_id1')(dense)\n",
    "#     drop_id = Dropout(0.5)(dense_id)\n",
    "    dense_id = Dense(16, activation='relu', kernel_initializer='random_uniform', name='dense_id2')(dense_id)\n",
    "#     drop_id = Dropout(0.5)(dense_id)\n",
    "\n",
    "    pid = Dense(classes, activation='softmax', kernel_initializer='random_uniform', name='pid_output')(dense_id)\n",
    "\n",
    "    dense_er = Dense(64, activation='relu', kernel_initializer='random_uniform', name='dense_er1')(dense)\n",
    "    dense_er = Dense(16, activation='relu', kernel_initializer='random_uniform', name='dense_er2')(dense_er)\n",
    "    \n",
    "    enreg = Dense(1, name='enreg_output')(dense_er)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=[pid, enreg])\n",
    "\n",
    "    model.compile(loss={'pid_output': 'categorical_crossentropy', 'enreg_output': 'mse'}, loss_weights={'pid_output': 1, 'enreg_output': 1}, optimizer='adam', metrics={'pid_output': 'accuracy', 'enreg_output': 'mse'})\n",
    "    return model\n",
    "\n",
    "model = full_model()\n",
    "model.summary()\n",
    "\n",
    "print(\"Model created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32400 samples, validate on 3600 samples\n",
      "Epoch 1/100\n",
      "32400/32400 [==============================] - 2s 69us/step - loss: 1.9079 - pid_output_loss: 1.2499 - enreg_output_loss: 0.6580 - pid_output_acc: 0.3014 - enreg_output_mean_squared_error: 0.6580 - val_loss: 2.6166 - val_pid_output_loss: 1.4591 - val_enreg_output_loss: 1.1576 - val_pid_output_acc: 0.0000e+00 - val_enreg_output_mean_squared_error: 1.1576\n",
      "Epoch 2/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 1.0241 - pid_output_loss: 0.7435 - enreg_output_loss: 0.2805 - pid_output_acc: 0.5992 - enreg_output_mean_squared_error: 0.2805 - val_loss: 2.3751 - val_pid_output_loss: 1.3485 - val_enreg_output_loss: 1.0266 - val_pid_output_acc: 0.9644 - val_enreg_output_mean_squared_error: 1.0266\n",
      "Epoch 3/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.7599 - pid_output_loss: 0.5208 - enreg_output_loss: 0.2390 - pid_output_acc: 0.7321 - enreg_output_mean_squared_error: 0.2390 - val_loss: 1.0914 - val_pid_output_loss: 0.0578 - val_enreg_output_loss: 1.0336 - val_pid_output_acc: 0.9925 - val_enreg_output_mean_squared_error: 1.0336\n",
      "Epoch 4/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6648 - pid_output_loss: 0.4359 - enreg_output_loss: 0.2289 - pid_output_acc: 0.7456 - enreg_output_mean_squared_error: 0.2289 - val_loss: 1.0578 - val_pid_output_loss: 0.0417 - val_enreg_output_loss: 1.0161 - val_pid_output_acc: 0.9944 - val_enreg_output_mean_squared_error: 1.0161\n",
      "Epoch 5/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6573 - pid_output_loss: 0.4310 - enreg_output_loss: 0.2263 - pid_output_acc: 0.7513 - enreg_output_mean_squared_error: 0.2263 - val_loss: 1.0497 - val_pid_output_loss: 0.0400 - val_enreg_output_loss: 1.0097 - val_pid_output_acc: 0.9931 - val_enreg_output_mean_squared_error: 1.0097\n",
      "Epoch 6/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6396 - pid_output_loss: 0.4243 - enreg_output_loss: 0.2153 - pid_output_acc: 0.7557 - enreg_output_mean_squared_error: 0.2153 - val_loss: 1.0303 - val_pid_output_loss: 0.0279 - val_enreg_output_loss: 1.0024 - val_pid_output_acc: 0.9942 - val_enreg_output_mean_squared_error: 1.0024\n",
      "Epoch 7/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6355 - pid_output_loss: 0.4220 - enreg_output_loss: 0.2135 - pid_output_acc: 0.7579 - enreg_output_mean_squared_error: 0.2135 - val_loss: 1.0499 - val_pid_output_loss: 0.0249 - val_enreg_output_loss: 1.0250 - val_pid_output_acc: 0.9942 - val_enreg_output_mean_squared_error: 1.0250\n",
      "Epoch 8/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6250 - pid_output_loss: 0.4184 - enreg_output_loss: 0.2066 - pid_output_acc: 0.7608 - enreg_output_mean_squared_error: 0.2066 - val_loss: 1.0282 - val_pid_output_loss: 0.0352 - val_enreg_output_loss: 0.9930 - val_pid_output_acc: 0.9908 - val_enreg_output_mean_squared_error: 0.9930\n",
      "Epoch 9/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6161 - pid_output_loss: 0.4156 - enreg_output_loss: 0.2005 - pid_output_acc: 0.7635 - enreg_output_mean_squared_error: 0.2005 - val_loss: 1.0978 - val_pid_output_loss: 0.0522 - val_enreg_output_loss: 1.0457 - val_pid_output_acc: 0.9864 - val_enreg_output_mean_squared_error: 1.0457\n",
      "Epoch 10/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6114 - pid_output_loss: 0.4138 - enreg_output_loss: 0.1976 - pid_output_acc: 0.7654 - enreg_output_mean_squared_error: 0.1976 - val_loss: 1.0194 - val_pid_output_loss: 0.0263 - val_enreg_output_loss: 0.9931 - val_pid_output_acc: 0.9919 - val_enreg_output_mean_squared_error: 0.9931\n",
      "Epoch 11/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6097 - pid_output_loss: 0.4148 - enreg_output_loss: 0.1949 - pid_output_acc: 0.7665 - enreg_output_mean_squared_error: 0.1949 - val_loss: 1.0269 - val_pid_output_loss: 0.0377 - val_enreg_output_loss: 0.9892 - val_pid_output_acc: 0.9894 - val_enreg_output_mean_squared_error: 0.9892\n",
      "Epoch 12/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6061 - pid_output_loss: 0.4104 - enreg_output_loss: 0.1956 - pid_output_acc: 0.7708 - enreg_output_mean_squared_error: 0.1956 - val_loss: 1.0396 - val_pid_output_loss: 0.0411 - val_enreg_output_loss: 0.9986 - val_pid_output_acc: 0.9867 - val_enreg_output_mean_squared_error: 0.9986\n",
      "Epoch 13/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.6015 - pid_output_loss: 0.4089 - enreg_output_loss: 0.1927 - pid_output_acc: 0.7716 - enreg_output_mean_squared_error: 0.1927 - val_loss: 1.0288 - val_pid_output_loss: 0.0359 - val_enreg_output_loss: 0.9929 - val_pid_output_acc: 0.9900 - val_enreg_output_mean_squared_error: 0.9929\n",
      "Epoch 14/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5980 - pid_output_loss: 0.4063 - enreg_output_loss: 0.1917 - pid_output_acc: 0.7750 - enreg_output_mean_squared_error: 0.1917 - val_loss: 0.9941 - val_pid_output_loss: 0.0193 - val_enreg_output_loss: 0.9748 - val_pid_output_acc: 0.9931 - val_enreg_output_mean_squared_error: 0.9748\n",
      "Epoch 15/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5956 - pid_output_loss: 0.4050 - enreg_output_loss: 0.1906 - pid_output_acc: 0.7765 - enreg_output_mean_squared_error: 0.1906 - val_loss: 1.0404 - val_pid_output_loss: 0.0400 - val_enreg_output_loss: 1.0004 - val_pid_output_acc: 0.9858 - val_enreg_output_mean_squared_error: 1.0004\n",
      "Epoch 16/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5938 - pid_output_loss: 0.4047 - enreg_output_loss: 0.1891 - pid_output_acc: 0.7779 - enreg_output_mean_squared_error: 0.1891 - val_loss: 1.0352 - val_pid_output_loss: 0.0315 - val_enreg_output_loss: 1.0037 - val_pid_output_acc: 0.9900 - val_enreg_output_mean_squared_error: 1.0037\n",
      "Epoch 17/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5917 - pid_output_loss: 0.4011 - enreg_output_loss: 0.1906 - pid_output_acc: 0.7806 - enreg_output_mean_squared_error: 0.1906 - val_loss: 1.0230 - val_pid_output_loss: 0.0300 - val_enreg_output_loss: 0.9930 - val_pid_output_acc: 0.9906 - val_enreg_output_mean_squared_error: 0.9930\n",
      "Epoch 18/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5897 - pid_output_loss: 0.4014 - enreg_output_loss: 0.1883 - pid_output_acc: 0.7816 - enreg_output_mean_squared_error: 0.1883 - val_loss: 0.9941 - val_pid_output_loss: 0.0211 - val_enreg_output_loss: 0.9731 - val_pid_output_acc: 0.9925 - val_enreg_output_mean_squared_error: 0.9731\n",
      "Epoch 19/100\n",
      "32400/32400 [==============================] - 1s 20us/step - loss: 0.5899 - pid_output_loss: 0.4033 - enreg_output_loss: 0.1866 - pid_output_acc: 0.7794 - enreg_output_mean_squared_error: 0.1866 - val_loss: 1.0189 - val_pid_output_loss: 0.0375 - val_enreg_output_loss: 0.9815 - val_pid_output_acc: 0.9897 - val_enreg_output_mean_squared_error: 0.9815\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_array, {'pid_output': pid_array, 'enreg_output': en_array_norm}, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)], shuffle=True, verbose=1)\n",
    "history_save = pd.DataFrame(history.history).to_hdf(save_dir + history_name + \".h5\", \"history\", append=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /data/user/adipilat/ParticleID/models/ \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "model.save(save_dir + model_name + \".h5\")\n",
    "print('Saved trained model at %s ' % save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 93 variables.\n",
      "INFO:tensorflow:Converted 93 variables to const ops.\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# save the frozen model\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, save_dir, model_name + \".pbtxt\", as_text=True)\n",
    "tf.train.write_graph(frozen_graph, save_dir, model_name + \".pb\", as_text=False)\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
